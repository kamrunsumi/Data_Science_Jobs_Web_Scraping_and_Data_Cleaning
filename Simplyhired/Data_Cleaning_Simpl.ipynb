{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "from dateutil.parser import parse \n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplyhired =pd.read_csv(\"file:///Users/manha/Desktop/DSE_6000/Active_Class/Project/Simplyhired/simplyhired_data_scientist.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4740, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4740 entries, 0 to 4739\n",
      "Data columns (total 8 columns):\n",
      "Job_Title           4740 non-null object\n",
      "Company_Name        4736 non-null object\n",
      "Location            4740 non-null object\n",
      "Date                4740 non-null object\n",
      "Job_Description     4736 non-null object\n",
      "Education           4740 non-null object\n",
      "Skill               4740 non-null object\n",
      "Estimated_Salary    4739 non-null object\n",
      "dtypes: object(8)\n",
      "memory usage: 296.3+ KB\n"
     ]
    }
   ],
   "source": [
    "print(simplyhired.shape)\n",
    "simplyhired.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1314, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dropping any duplicate rows:\n",
    "simplyhired = simplyhired.drop_duplicates()\n",
    "simplyhired.reset_index(drop=True, inplace=True)\n",
    "simplyhired.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job_Title           0\n",
       "Company_Name        4\n",
       "Location            0\n",
       "Date                0\n",
       "Job_Description     4\n",
       "Education           0\n",
       "Skill               0\n",
       "Estimated_Salary    1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplyhired.isnull().values.any()\n",
    "simplyhired.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simplyhired['Estimated_Salary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some targeted cleaning of salary information to make parsing easier #—> remove “\\n”, “$”, and “,”\n",
    "simplyhired['Estimated_Salary'] = simplyhired['Estimated_Salary'].str.replace('\\n', '')\n",
    "simplyhired['Estimated_Salary'] = simplyhired['Estimated_Salary'].str.replace(',', '')\n",
    "simplyhired['Estimated_Salary']= simplyhired['Estimated_Salary'].str.replace('$', '')\n",
    "simplyhired['Estimated_Salary']= simplyhired['Estimated_Salary'].str.replace('Estimated:', '')\n",
    "#simplyhired.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_hour_salaries = simplyhired[simplyhired[\"Estimated_Salary\"].str.contains('hour',na=False)]\n",
    "\n",
    "simplyhired['salary_period'] = np.nan\n",
    "#if the salary contains information on time period, save that time\n",
    "#period string in the og_salary_period column\n",
    "simplyhired.loc[simplyhired['Estimated_Salary'].str.contains('year',na=False), 'salary_period'] ='year'\n",
    "simplyhired.loc[simplyhired['Estimated_Salary'].str.contains('month',na=False), 'salary_period'] ='month'\n",
    "simplyhired.loc[simplyhired['Estimated_Salary'].str.contains('week',na=False), 'salary_period'] = 'week'\n",
    "simplyhired.loc[simplyhired['Estimated_Salary'].str.contains('day',na=False), 'salary_period'] = 'day'\n",
    "simplyhired.loc[simplyhired['Estimated_Salary'].str.contains('hour', na=False), 'salary_period'] ='hour'\n",
    "simplyhired.loc[simplyhired['salary_period'].str.contains('NaN',na=True), 'salary_period'] ='Nothing_found'\n",
    "#remove extra information from salary data\n",
    "simplyhired['Estimated_Salary']= simplyhired['Estimated_Salary'].str.replace('year', '')\n",
    "simplyhired['Estimated_Salary']= simplyhired['Estimated_Salary'].str.replace('a', '')\n",
    "#simplyhired['Estimated_Salary']= simplyhired['Estimated_Salary'].str.replace('hour', '')\n",
    "#simplyhired['Estimated_Salary']= simplyhired['Estimated_Salary'].str.replace('n hour', '')\n",
    "#print(hour_salaries)\n",
    "#simplyhired.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15       55 - 75 \n",
      "25            42 \n",
      "28       60 - 65 \n",
      "29       50 - 80 \n",
      "43     100 - 150 \n",
      "46       50 - 60 \n",
      "52       65 - 75 \n",
      "55            30 \n",
      "57       33 - 46 \n",
      "79       60 - 70 \n",
      "133           85 \n",
      "277      50 - 52 \n",
      "280      28 - 34 \n",
      "324      40 - 50 \n",
      "330      20 - 60 \n",
      "376      23 - 34 \n",
      "589           48 \n",
      "762      46 - 48 \n",
      "813      60 - 75 \n",
      "843           37 \n",
      "Name: Estimated_Salary, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#hour_salaries = simplyhired[simplyhired[\"Estimated_Salary\"].str.contains('hour',na=False)]\n",
    "#print(hour_salaries)\n",
    "sim_hour_salaries[\"Estimated_Salary\"] =sim_hour_salaries[\"Estimated_Salary\"].str.replace('an hour', '')\n",
    "print(sim_hour_salaries[\"Estimated_Salary\"])\n",
    "\n",
    "\n",
    "#simplyhired['Estimated_Salary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "def split_sal(i):\n",
    "    #print(i)\n",
    "    #type(i)\n",
    "    try:\n",
    "        splt = i.split('-',1)\n",
    "        #print(splt)\n",
    "        first = float(splt[0])\n",
    "        #print(first)\n",
    "        second = float(splt[1])\n",
    "        #print(second)\n",
    "        return (first + second)/2\n",
    "    except:\n",
    "        return float(i)\n",
    "\n",
    "sim_hour_salaries['Estimated_Salary'] =sim_hour_salaries['Estimated_Salary'].apply(split_sal)\n",
    "#print(sim_hour_salaries['Estimated_Salary'] )\n",
    "\n",
    "sim_hour_salaries['Estimated_Salary']=sim_hour_salaries['Estimated_Salary'] * 2080\n",
    "#print(sim_hour_salaries['Estimated_Salary'])\n",
    "\n",
    "#hour_salaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>Education</th>\n",
       "      <th>Skill</th>\n",
       "      <th>Estimated_Salary</th>\n",
       "      <th>salary_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Degreed</td>\n",
       "      <td>Remote</td>\n",
       "      <td>&lt;time datetime=\"2019-09-24T02:26:53Z\" itemprop...</td>\n",
       "      <td>SkillsSQLCommunication SkillsClusteringNatural...</td>\n",
       "      <td>SQLCommunication SkillsClusteringNatural Langu...</td>\n",
       "      <td>SkillsSQLCommunication SkillsClusteringNatural...</td>\n",
       "      <td>110000 - 140000</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entry Level Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>United States</td>\n",
       "      <td>&lt;time datetime=\"2019-08-03T10:12:38Z\" itemprop...</td>\n",
       "      <td>EducationMaster's DegreeSkillsDoD ExperienceSu...</td>\n",
       "      <td>Master's Degree</td>\n",
       "      <td>EducationMaster's DegreeSkillsDoD ExperienceSu...</td>\n",
       "      <td>94000 - 130000</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Nationwide Opportunities</td>\n",
       "      <td>Amazon Web Services, Inc.</td>\n",
       "      <td>Florida +42 locations</td>\n",
       "      <td>&lt;time datetime=\"2019-06-21T07:53:00Z\" itemprop...</td>\n",
       "      <td>EducationBachelor's DegreeSkillsCommunication ...</td>\n",
       "      <td>Bachelor's Degree</td>\n",
       "      <td>EducationBachelor's DegreeSkillsCommunication ...</td>\n",
       "      <td>91000 - 130000</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>Numerdox</td>\n",
       "      <td>Sacramento, CA</td>\n",
       "      <td>&lt;time datetime=\"2018-11-15T08:11:28Z\" itemprop...</td>\n",
       "      <td>SkillsSQL401(k)HadoopAWSSparkBenefitsFlexible ...</td>\n",
       "      <td>SQL401(k)HadoopAWSSpark</td>\n",
       "      <td>SkillsSQL401(k)HadoopAWSSparkBenefitsFlexible ...</td>\n",
       "      <td>110000 - 160000</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Quaxigma</td>\n",
       "      <td>Schaumburg, IL</td>\n",
       "      <td>&lt;time datetime=\"2019-08-18T20:12:53Z\" itemprop...</td>\n",
       "      <td>EducationMaster's DegreeDoctoral DegreeSkillsS...</td>\n",
       "      <td>Master's DegreeDoctoral Degree</td>\n",
       "      <td>EducationMaster's DegreeDoctoral DegreeSkillsS...</td>\n",
       "      <td>96000 - 130000</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job_Title               Company_Name  \\\n",
       "0                             Data Scientist                    Degreed   \n",
       "1                 Entry Level Data Scientist                        IBM   \n",
       "2  Data Scientist - Nationwide Opportunities  Amazon Web Services, Inc.   \n",
       "3               Data Scientist - Entry Level                   Numerdox   \n",
       "4                             Data Scientist                   Quaxigma   \n",
       "\n",
       "                Location                                               Date  \\\n",
       "0                 Remote  <time datetime=\"2019-09-24T02:26:53Z\" itemprop...   \n",
       "1          United States  <time datetime=\"2019-08-03T10:12:38Z\" itemprop...   \n",
       "2  Florida +42 locations  <time datetime=\"2019-06-21T07:53:00Z\" itemprop...   \n",
       "3         Sacramento, CA  <time datetime=\"2018-11-15T08:11:28Z\" itemprop...   \n",
       "4         Schaumburg, IL  <time datetime=\"2019-08-18T20:12:53Z\" itemprop...   \n",
       "\n",
       "                                     Job_Description  \\\n",
       "0  SkillsSQLCommunication SkillsClusteringNatural...   \n",
       "1  EducationMaster's DegreeSkillsDoD ExperienceSu...   \n",
       "2  EducationBachelor's DegreeSkillsCommunication ...   \n",
       "3  SkillsSQL401(k)HadoopAWSSparkBenefitsFlexible ...   \n",
       "4  EducationMaster's DegreeDoctoral DegreeSkillsS...   \n",
       "\n",
       "                                           Education  \\\n",
       "0  SQLCommunication SkillsClusteringNatural Langu...   \n",
       "1                                    Master's Degree   \n",
       "2                                  Bachelor's Degree   \n",
       "3                            SQL401(k)HadoopAWSSpark   \n",
       "4                     Master's DegreeDoctoral Degree   \n",
       "\n",
       "                                               Skill    Estimated_Salary  \\\n",
       "0  SkillsSQLCommunication SkillsClusteringNatural...   110000 - 140000     \n",
       "1  EducationMaster's DegreeSkillsDoD ExperienceSu...    94000 - 130000     \n",
       "2  EducationBachelor's DegreeSkillsCommunication ...    91000 - 130000     \n",
       "3  SkillsSQL401(k)HadoopAWSSparkBenefitsFlexible ...   110000 - 160000     \n",
       "4  EducationMaster's DegreeDoctoral DegreeSkillsS...    96000 - 130000     \n",
       "\n",
       "  salary_period  \n",
       "0          year  \n",
       "1          year  \n",
       "2          year  \n",
       "3          year  \n",
       "4          year  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#rejoining salary data into main scrape_data df\n",
    "combined_salaries = pd.concat([sim_hour_salaries], axis=0, sort=False)\n",
    "sf = pd.concat([simplyhired, combined_salaries], axis=0, sort= False)\n",
    "sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf['Estimated_Salary']= sf['Estimated_Salary'].str.replace('n hour', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sal(i):\n",
    "    #print(i)\n",
    "    #type(i)\n",
    "    try:\n",
    "        splt = i.split('-',1)\n",
    "        #print(splt)\n",
    "        first = float(splt[0])\n",
    "        #print(first)\n",
    "        second = float(splt[1])\n",
    "        #print(second)\n",
    "        return (first + second)/2\n",
    "    except:\n",
    "        return float(i)\n",
    "\n",
    "sf['Estimated_Salary'] = sf['Estimated_Salary'].apply(split_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 15,  25,  28,  29,  43,  46,  52,  55,  57,  79, 133, 277, 280,\n",
      "            324, 330, 376, 589, 762, 813, 843],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "#sf['Estimated_Salary'].value_counts()\n",
    "# Get names of indexes for which column Age has value 30\n",
    "indexNames = sf[ sf['Estimated_Salary'] <= 300 ].index\n",
    "print(indexNames)\n",
    " \n",
    "# Delete these row indexes from dataFrame\n",
    "sf.drop(indexNames , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sf['Estimated_Salary'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>Estimated_Salary</th>\n",
       "      <th>salary_period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Degreed</td>\n",
       "      <td>Remote</td>\n",
       "      <td>SkillsSQLCommunication SkillsClusteringNatural...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entry Level Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>United States</td>\n",
       "      <td>EducationMaster's DegreeSkillsDoD ExperienceSu...</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Nationwide Opportunities</td>\n",
       "      <td>Amazon Web Services, Inc.</td>\n",
       "      <td>Florida +42 locations</td>\n",
       "      <td>EducationBachelor's DegreeSkillsCommunication ...</td>\n",
       "      <td>110500.0</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>Numerdox</td>\n",
       "      <td>Sacramento, CA</td>\n",
       "      <td>SkillsSQL401(k)HadoopAWSSparkBenefitsFlexible ...</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Quaxigma</td>\n",
       "      <td>Schaumburg, IL</td>\n",
       "      <td>EducationMaster's DegreeDoctoral DegreeSkillsS...</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>year</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job_Title               Company_Name  \\\n",
       "0                             Data Scientist                    Degreed   \n",
       "1                 Entry Level Data Scientist                        IBM   \n",
       "2  Data Scientist - Nationwide Opportunities  Amazon Web Services, Inc.   \n",
       "3               Data Scientist - Entry Level                   Numerdox   \n",
       "4                             Data Scientist                   Quaxigma   \n",
       "\n",
       "                Location                                    Job_Description  \\\n",
       "0                 Remote  SkillsSQLCommunication SkillsClusteringNatural...   \n",
       "1          United States  EducationMaster's DegreeSkillsDoD ExperienceSu...   \n",
       "2  Florida +42 locations  EducationBachelor's DegreeSkillsCommunication ...   \n",
       "3         Sacramento, CA  SkillsSQL401(k)HadoopAWSSparkBenefitsFlexible ...   \n",
       "4         Schaumburg, IL  EducationMaster's DegreeDoctoral DegreeSkillsS...   \n",
       "\n",
       "   Estimated_Salary salary_period  \n",
       "0          125000.0          year  \n",
       "1          112000.0          year  \n",
       "2          110500.0          year  \n",
       "3          135000.0          year  \n",
       "4          113000.0          year  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf.drop('Education', axis=1, inplace=True)\n",
    "sf.drop('Skill', axis=1, inplace=True)\n",
    "sf.drop('Date', axis=1, inplace=True)\n",
    "sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating data character cleaning function, and applying to all \n",
    "#columns, also lowercasing all string data for ease of later nlp\n",
    "def data_clean(df, column):\n",
    "    cleaning_list = ['+', '$','/',',','?','.',';','-','@','!','&','%','^','*',')','(', '\\n']\n",
    "    for item in cleaning_list:\n",
    "        df[column] = df[column].str.replace(item, '')\n",
    "##can’t clean the salary column due to float values, and don’t need \n",
    "#to clean og_salary, so keeping out of the for loop\n",
    "for column in simplyhired.columns[0:len(simplyhired.columns)-2]:\n",
    "    data_clean(simplyhired, column)\n",
    "#indeed.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Atlanta, GA                     82\n",
       "Chicago, IL                     75\n",
       "San Francisco, CA               58\n",
       "New York, NY                    54\n",
       "Livermore, CA                   52\n",
       "Rolling Meadows, IL             41\n",
       "San Jose, CA                    39\n",
       "United States                   34\n",
       "Washington, DC                  31\n",
       "Boston, MA                      28\n",
       "Seattle, WA                     23\n",
       "Tampa, FL                       22\n",
       "Sunnyvale, CA                   21\n",
       "Marshfield, WI                  19\n",
       "Lake Mary, FL                   19\n",
       "Amherst, MA                     16\n",
       "Menlo Park, CA                  15\n",
       "Austin, TX                      13\n",
       "Pittsburgh, PA                  13\n",
       "Denver, CO                      13\n",
       "Arlington, VA                   11\n",
       "Houston, TX                     11\n",
       "Pasadena, CA                    11\n",
       "Cincinnati, OH                  10\n",
       "Remote                           8\n",
       "Palo Alto, CA                    7\n",
       "McLean, VA                       7\n",
       "San Diego, CA                    7\n",
       "Reston, VA                       7\n",
       "Bethesda, MD                     7\n",
       "                                ..\n",
       "Lisle, IL                        1\n",
       "Aberdeen Proving Ground, MD      1\n",
       "Livonia, MI                      1\n",
       "Washington, DC +15 locations     1\n",
       "Chantilly, VA +6 locations       1\n",
       "Berkeley, CA                     1\n",
       "Pleasanton, CA                   1\n",
       "Piscataway, NJ                   1\n",
       "Jupiter, FL                      1\n",
       "Malibu, CA                       1\n",
       "Devens, MA                       1\n",
       "Wickliffe, OH                    1\n",
       "New Jersey                       1\n",
       "Northridge, CA                   1\n",
       "Lakewood, CO                     1\n",
       "Fort Wayne, IN                   1\n",
       "Cape Canaveral, FL               1\n",
       "Hawaii +12 locations             1\n",
       "Vacaville, CA                    1\n",
       "Knoxville, TN                    1\n",
       "Niceville, FL                    1\n",
       "Sacramento, CA                   1\n",
       "Franklin, TN                     1\n",
       "Chevy Chase, MD                  1\n",
       "Bend, OR                         1\n",
       "Southfield, MI                   1\n",
       "Research Triangle Park, NC       1\n",
       "Dublin, CA                       1\n",
       "Mettawa, IL +1 location          1\n",
       "Newark, CA                       1\n",
       "Name: Location, Length: 369, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf['Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating data character cleaning function, and applying to all \n",
    "\n",
    "cleaning_list = ['1 location ',' 2 locations ' ]\n",
    "for item in cleaning_list:\n",
    "    sf[\"Location\"] = sf[\"Location\"].str.replace(item,'' )\n",
    "\n",
    "#indeed.head()\n",
    "#sf['Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf['State'] = np.nan\n",
    "#if the salary contains information on time period, save that time\n",
    "#period string in the og_salary_period column\n",
    "sf.loc[sf['Location'].str.contains('PA',na=False), 'State'] ='PA'\n",
    "sf.loc[sf['Location'].str.contains('MA',na=False), 'State'] ='MA'\n",
    "sf.loc[sf['Location'].str.contains('TX',na=False), 'State'] ='TX'\n",
    "sf.loc[sf['Location'].str.contains('FL',na=False), 'State'] ='FL'\n",
    "sf.loc[sf['Location'].str.contains('MO',na=False), 'State'] ='MO'\n",
    "sf.loc[sf['Location'].str.contains('IN',na=False), 'State'] ='IN'\n",
    "sf.loc[sf['Location'].str.contains('MN',na=False), 'State'] ='MN'\n",
    "sf.loc[sf['Location'].str.contains('CO',na=False), 'State'] ='CO'\n",
    "sf.loc[sf['Location'].str.contains('FL',na=False), 'State'] ='DC'\n",
    "sf.loc[sf['Location'].str.contains('NJ',na=False), 'State'] ='NJ'\n",
    "sf.loc[sf['Location'].str.contains('AZ',na=False), 'State'] ='AZ'\n",
    "sf.loc[sf['Location'].str.contains('MI',na=False), 'State'] ='MI'\n",
    "sf.loc[sf['Location'].str.contains('MD',na=False), 'State'] ='MD'\n",
    "sf.loc[sf['Location'].str.contains('WA',na=False), 'State'] ='WA'\n",
    "sf.loc[sf['Location'].str.contains('TN',na=False), 'State'] ='TN'\n",
    "sf.loc[sf['Location'].str.contains('SD',na=False), 'State'] ='SD'\n",
    "sf.loc[sf['Location'].str.contains('CT',na=False), 'State'] ='CT'\n",
    "sf.loc[sf['Location'].str.contains('VA',na=False), 'State'] ='VA'\n",
    "sf.loc[sf['Location'].str.contains('OH',na=False), 'State'] ='OH'\n",
    "sf.loc[sf['Location'].str.contains('WI',na=False), 'State'] ='WI'\n",
    "sf.loc[sf['Location'].str.contains('NY',na=False), 'State'] ='NY'\n",
    "sf.loc[sf['Location'].str.contains('IL',na=False), 'State'] ='IL'\n",
    "sf.loc[sf['Location'].str.contains('OR',na=False), 'State'] ='OR'\n",
    "sf.loc[sf['Location'].str.contains('IA',na=False), 'State'] ='IA'\n",
    "sf.loc[sf['Location'].str.contains('WV',na=False), 'State'] ='WV'\n",
    "sf.loc[sf['Location'].str.contains('IN',na=False), 'State'] ='IN'\n",
    "sf.loc[sf['Location'].str.contains('CA',na=False), 'State'] ='CA'\n",
    "sf.loc[sf['Location'].str.contains('United States',na=False), 'State'] ='United States'\n",
    "sf.loc[sf['Location'].str.contains('Colorado',na=False), 'State'] ='CO'\n",
    "sf.loc[sf['State'].str.contains('NaN',na=True), 'State'] ='Not Mention'\n",
    "#simplyhired.head()\n",
    "#sf['Location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CA               296\n",
       "Not Mention      201\n",
       "IL               142\n",
       "VA                80\n",
       "NY                70\n",
       "DC                66\n",
       "MA                62\n",
       "TX                53\n",
       "MD                41\n",
       "United States     36\n",
       "WA                33\n",
       "OH                33\n",
       "MI                31\n",
       "CO                29\n",
       "WI                25\n",
       "PA                25\n",
       "NJ                17\n",
       "IN                 9\n",
       "CT                 9\n",
       "MO                 8\n",
       "OR                 6\n",
       "TN                 6\n",
       "MN                 5\n",
       "AZ                 4\n",
       "SD                 3\n",
       "WV                 2\n",
       "IA                 2\n",
       "Name: State, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf['State'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>Estimated_Salary</th>\n",
       "      <th>salary_period</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Degreed</td>\n",
       "      <td>Remote</td>\n",
       "      <td>SkillsSQLCommunication SkillsClusteringNatural...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>year</td>\n",
       "      <td>Not Mention</td>\n",
       "      <td>Remote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entry Level Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>United States</td>\n",
       "      <td>EducationMaster's DegreeSkillsDoD ExperienceSu...</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>year</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Nationwide Opportunities</td>\n",
       "      <td>Amazon Web Services, Inc.</td>\n",
       "      <td>Florida +42 locations</td>\n",
       "      <td>EducationBachelor's DegreeSkillsCommunication ...</td>\n",
       "      <td>110500.0</td>\n",
       "      <td>year</td>\n",
       "      <td>Not Mention</td>\n",
       "      <td>Not Mention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>Numerdox</td>\n",
       "      <td>Sacramento, CA</td>\n",
       "      <td>SkillsSQL401(k)HadoopAWSSparkBenefitsFlexible ...</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>year</td>\n",
       "      <td>CA</td>\n",
       "      <td>Not Mention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Quaxigma</td>\n",
       "      <td>Schaumburg, IL</td>\n",
       "      <td>EducationMaster's DegreeDoctoral DegreeSkillsS...</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>year</td>\n",
       "      <td>IL</td>\n",
       "      <td>Not Mention</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job_Title               Company_Name  \\\n",
       "0                             Data Scientist                    Degreed   \n",
       "1                 Entry Level Data Scientist                        IBM   \n",
       "2  Data Scientist - Nationwide Opportunities  Amazon Web Services, Inc.   \n",
       "3               Data Scientist - Entry Level                   Numerdox   \n",
       "4                             Data Scientist                   Quaxigma   \n",
       "\n",
       "                Location                                    Job_Description  \\\n",
       "0                 Remote  SkillsSQLCommunication SkillsClusteringNatural...   \n",
       "1          United States  EducationMaster's DegreeSkillsDoD ExperienceSu...   \n",
       "2  Florida +42 locations  EducationBachelor's DegreeSkillsCommunication ...   \n",
       "3         Sacramento, CA  SkillsSQL401(k)HadoopAWSSparkBenefitsFlexible ...   \n",
       "4         Schaumburg, IL  EducationMaster's DegreeDoctoral DegreeSkillsS...   \n",
       "\n",
       "   Estimated_Salary salary_period          State           City  \n",
       "0          125000.0          year    Not Mention         Remote  \n",
       "1          112000.0          year  United States  United States  \n",
       "2          110500.0          year    Not Mention    Not Mention  \n",
       "3          135000.0          year             CA    Not Mention  \n",
       "4          113000.0          year             IL    Not Mention  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simplyhired['City'] = np.nan\n",
    "#if the salary contains information on time period, save that time\n",
    "#period string in the og_salary_period column\n",
    "sf.loc[sf['Location'].str.contains('Atlanta',na=False), 'City'] ='Atlanta'\n",
    "sf.loc[sf['Location'].str.contains('Chicago',na=False), 'City'] ='Chicago'\n",
    "sf.loc[sf['Location'].str.contains('San Francisco',na=False), 'City'] ='San Francisco'\n",
    "sf.loc[sf['Location'].str.contains('New York',na=False), 'City'] ='New York'\n",
    "sf.loc[sf['Location'].str.contains('Livermore',na=False), 'City'] ='Livermore'\n",
    "sf.loc[sf['Location'].str.contains('Redwood City',na=False), 'City'] ='Redwood City'\n",
    "sf.loc[sf['Location'].str.contains('Maplewood',na=False), 'City'] ='Maplewood'\n",
    "sf.loc[sf['Location'].str.contains('Indianapolis',na=False), 'City'] ='Indianapolis'\n",
    "sf.loc[sf['Location'].str.contains('Colorado',na=False), 'City'] ='Colorado'\n",
    "sf.loc[sf['Location'].str.contains('Oshkosh',na=False), 'City'] ='Oshkosh'\n",
    "sf.loc[sf['Location'].str.contains('Memphis',na=False), 'City'] ='Memphis'\n",
    "sf.loc[sf['Location'].str.contains('Delafield',na=False), 'City'] ='Delafield'\n",
    "sf.loc[sf['Location'].str.contains('Woodcliff',na=False), 'City'] ='Woodcliff'\n",
    "sf.loc[sf['Location'].str.contains('Tempe',na=False), 'City'] ='Tempe'\n",
    "sf.loc[sf['Location'].str.contains('Morrisville',na=False), 'City'] ='Morrisville'\n",
    "sf.loc[sf['Location'].str.contains('Fishers',na=False), 'City'] ='Fishers'\n",
    "sf.loc[sf['Location'].str.contains('Chester',na=False), 'City'] ='Chester'\n",
    "sf.loc[sf['Location'].str.contains('Johnston',na=False), 'City'] ='Johnston'\n",
    "sf.loc[sf['Location'].str.contains('Aguadilla',na=False), 'City'] ='Aguadilla'\n",
    "sf.loc[sf['Location'].str.contains('Brookfield',na=False), 'City'] ='Brookfield'\n",
    "sf.loc[sf['Location'].str.contains('Malibu',na=False), 'City'] ='Malibu'\n",
    "sf.loc[sf['Location'].str.contains('Bridgeport',na=False), 'City'] ='Bridgeport'\n",
    "sf.loc[sf['Location'].str.contains('Ada',na=False), 'City'] ='Ada'\n",
    "sf.loc[sf['Location'].str.contains('Urbandale',na=False), 'City'] ='Urbandale'\n",
    "sf.loc[sf['Location'].str.contains('Englewood',na=False), 'City'] ='Englewood'\n",
    "sf.loc[sf['Location'].str.contains('Quantico',na=False), 'City'] ='Quantico'\n",
    "sf.loc[sf['Location'].str.contains('Albany',na=False), 'City'] ='Albany'\n",
    "sf.loc[sf['Location'].str.contains('Chantilly',na=False), 'City'] ='Chantilly'\n",
    "sf.loc[sf['Location'].str.contains('Alpharetta',na=False), 'City'] ='Alpharetta'\n",
    "sf.loc[sf['Location'].str.contains('Culver City',na=False), 'City'] ='Culver City'\n",
    "sf.loc[sf['Location'].str.contains('Hartford',na=False), 'City'] ='Hartford'\n",
    "sf.loc[sf['Location'].str.contains('Bethesda',na=False), 'City'] ='Bethesda'\n",
    "sf.loc[sf['Location'].str.contains('Reston',na=False), 'City'] ='Reston'\n",
    "sf.loc[sf['Location'].str.contains('San Diego',na=False), 'City'] ='San Diego'\n",
    "sf.loc[sf['Location'].str.contains('Ann Arbor',na=False), 'City'] ='Ann Arbor'\n",
    "sf.loc[sf['Location'].str.contains('McLean',na=False), 'City'] ='McLean'\n",
    "sf.loc[sf['Location'].str.contains('Remote',na=False), 'City'] ='Remote'\n",
    "sf.loc[sf['Location'].str.contains('Cincinnati',na=False), 'City'] ='Cincinnati'\n",
    "sf.loc[sf['Location'].str.contains('Arlington',na=False), 'City'] ='Arlington'\n",
    "sf.loc[sf['Location'].str.contains('Houston',na=False), 'City'] ='Houston'\n",
    "sf.loc[sf['Location'].str.contains('Pasadena',na=False), 'City'] ='Pasadena'\n",
    "sf.loc[sf['Location'].str.contains('Austin',na=False), 'City'] ='Austin'\n",
    "sf.loc[sf['Location'].str.contains('Denver',na=False), 'City'] ='Denver'\n",
    "sf.loc[sf['Location'].str.contains('Menlo Park',na=False), 'City'] ='Menlo Park'\n",
    "sf.loc[sf['Location'].str.contains('Pittsburgh',na=False), 'City'] ='Pittsburgh'\n",
    "sf.loc[sf['Location'].str.contains('Amherst',na=False), 'City'] ='Amherst'\n",
    "sf.loc[sf['Location'].str.contains('Marshfield',na=False), 'City'] ='Marshfield'\n",
    "sf.loc[sf['Location'].str.contains('Lake Mary',na=False), 'City'] ='Lake Mary'\n",
    "sf.loc[sf['Location'].str.contains('Sunnyvale',na=False), 'City'] ='Sunnyvale'\n",
    "sf.loc[sf['Location'].str.contains('Tampa',na=False), 'City'] ='Tampa'\n",
    "sf.loc[sf['Location'].str.contains('Seattle',na=False), 'City'] ='Seattle'\n",
    "sf.loc[sf['Location'].str.contains('Boston',na=False), 'City'] ='Boston'\n",
    "sf.loc[sf['Location'].str.contains('Washington',na=False), 'City'] ='Washington'\n",
    "sf.loc[sf['Location'].str.contains('San Jose',na=False), 'City'] ='San Jose'\n",
    "sf.loc[sf['Location'].str.contains('Rolling Meadows',na=False), 'City'] ='Rolling Meadows'\n",
    "sf.loc[sf['Location'].str.contains('Reston',na=False), 'City'] ='Reston'\n",
    "sf.loc[sf['Location'].str.contains('San Diego',na=False), 'City'] ='San Diego'\n",
    "sf.loc[sf['Location'].str.contains('Ann Arbor',na=False), 'City'] ='Ann Arbor'\n",
    "sf.loc[sf['Location'].str.contains('McLean',na=False), 'City'] ='McLean'\n",
    "sf.loc[sf['Location'].str.contains('Remote',na=False), 'City'] ='Remote'\n",
    "sf.loc[sf['Location'].str.contains('Cincinnati',na=False), 'City'] ='Cincinnati'\n",
    "sf.loc[sf['Location'].str.contains('Arlington',na=False), 'City'] ='Arlington'\n",
    "sf.loc[sf['Location'].str.contains('Houston',na=False), 'City'] ='Houston'\n",
    "sf.loc[sf['Location'].str.contains('Pasadena',na=False), 'City'] ='Pasadena'\n",
    "sf.loc[sf['Location'].str.contains('Austin',na=False), 'City'] ='Austin'\n",
    "sf.loc[sf['Location'].str.contains('Denver',na=False), 'City'] ='Denver'\n",
    "sf.loc[sf['Location'].str.contains('United States',na=False), 'City'] ='United States'\n",
    "sf.loc[sf['City'].str.contains('NaN',na=True), 'City'] ='Not Mention'\n",
    "\n",
    "\n",
    "sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Name</th>\n",
       "      <th>Location</th>\n",
       "      <th>Job_Description</th>\n",
       "      <th>Estimated_Salary</th>\n",
       "      <th>salary_period</th>\n",
       "      <th>State</th>\n",
       "      <th>City</th>\n",
       "      <th>Python</th>\n",
       "      <th>SQL</th>\n",
       "      <th>NoSQL</th>\n",
       "      <th>java</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Degreed</td>\n",
       "      <td>Remote</td>\n",
       "      <td>SkillsSQLCommunication SkillsClusteringNatural...</td>\n",
       "      <td>125000.0</td>\n",
       "      <td>year</td>\n",
       "      <td>Not Mention</td>\n",
       "      <td>Remote</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Entry Level Data Scientist</td>\n",
       "      <td>IBM</td>\n",
       "      <td>United States</td>\n",
       "      <td>EducationMaster's DegreeSkillsDoD ExperienceSu...</td>\n",
       "      <td>112000.0</td>\n",
       "      <td>year</td>\n",
       "      <td>United States</td>\n",
       "      <td>United States</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist - Nationwide Opportunities</td>\n",
       "      <td>Amazon Web Services, Inc.</td>\n",
       "      <td>Florida +42 locations</td>\n",
       "      <td>EducationBachelor's DegreeSkillsCommunication ...</td>\n",
       "      <td>110500.0</td>\n",
       "      <td>year</td>\n",
       "      <td>Not Mention</td>\n",
       "      <td>Not Mention</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Entry Level</td>\n",
       "      <td>Numerdox</td>\n",
       "      <td>Sacramento, CA</td>\n",
       "      <td>SkillsSQL401(k)HadoopAWSSparkBenefitsFlexible ...</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>year</td>\n",
       "      <td>CA</td>\n",
       "      <td>Not Mention</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Quaxigma</td>\n",
       "      <td>Schaumburg, IL</td>\n",
       "      <td>EducationMaster's DegreeDoctoral DegreeSkillsS...</td>\n",
       "      <td>113000.0</td>\n",
       "      <td>year</td>\n",
       "      <td>IL</td>\n",
       "      <td>Not Mention</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job_Title               Company_Name  \\\n",
       "0                             Data Scientist                    Degreed   \n",
       "1                 Entry Level Data Scientist                        IBM   \n",
       "2  Data Scientist - Nationwide Opportunities  Amazon Web Services, Inc.   \n",
       "3               Data Scientist - Entry Level                   Numerdox   \n",
       "4                             Data Scientist                   Quaxigma   \n",
       "\n",
       "                Location                                    Job_Description  \\\n",
       "0                 Remote  SkillsSQLCommunication SkillsClusteringNatural...   \n",
       "1          United States  EducationMaster's DegreeSkillsDoD ExperienceSu...   \n",
       "2  Florida +42 locations  EducationBachelor's DegreeSkillsCommunication ...   \n",
       "3         Sacramento, CA  SkillsSQL401(k)HadoopAWSSparkBenefitsFlexible ...   \n",
       "4         Schaumburg, IL  EducationMaster's DegreeDoctoral DegreeSkillsS...   \n",
       "\n",
       "   Estimated_Salary salary_period          State           City Python SQL  \\\n",
       "0          125000.0          year    Not Mention         Remote      1   1   \n",
       "1          112000.0          year  United States  United States      0   0   \n",
       "2          110500.0          year    Not Mention    Not Mention      0   0   \n",
       "3          135000.0          year             CA    Not Mention      1   1   \n",
       "4          113000.0          year             IL    Not Mention      1   1   \n",
       "\n",
       "  NoSQL java  \n",
       "0     0    0  \n",
       "1     0    0  \n",
       "2     0    0  \n",
       "3     0    0  \n",
       "4     0    1  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sf['Python'] = np.nan\n",
    "#if the salary contains information on time period, save that time\n",
    "#period string in the og_salary_period column\n",
    "sf.loc[sf['Job_Description'].str.contains('Python',na=False), 'Python'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('python',na=False), 'Python'] ='1'\n",
    "sf.loc[sf['Python'].str.contains('NaN',na=True), 'Python'] ='0'\n",
    "sf['SQL'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('SQL',na=False), 'SQL'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('sql',na=False), 'SQL'] ='1'\n",
    "sf.loc[sf['SQL'].str.contains('NaN',na=True), 'SQL'] ='0'\n",
    "sf['NoSQL'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('NoSQL',na=False), 'NoSQL'] ='1'\n",
    "sf.loc[sf['NoSQL'].str.contains('NaN',na=True), 'NoSQL'] ='0'\n",
    "sf['java'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('java',na=False), 'java'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('JavaScript',na=False), 'java'] ='1'\n",
    "sf.loc[sf['java'].str.contains('NaN',na=True), 'java'] ='0'\n",
    "sf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf['swift'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Swift',na=False), 'swift'] ='1'\n",
    "sf.loc[sf['swift'].str.contains('NaN',na=True), 'swift'] ='0'\n",
    "sf['PHP'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('PHP',na=False), 'PHP'] ='1'\n",
    "sf.loc[sf['PHP'].str.contains('NaN',na=True), 'PHP'] ='0'\n",
    "\n",
    "sf['R'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('R',na=False), 'R'] ='1'\n",
    "sf.loc[sf['R'].str.contains('NaN',na=True), 'R'] ='0'\n",
    "#indeed.head()\n",
    "\n",
    "#indeed.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf['Project_Management'] = np.nan\n",
    "#if the salary contains information on time period, save that time\n",
    "#period string in the og_salary_period column\n",
    "#def main():\n",
    "   # foo = \"\"\"Project Management\"\"\"\n",
    "sf.loc[sf['Job_Description'].str.contains('Project Management',na=False), 'Project_Management'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('ProjectManagement',na=False), 'Project_Management'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('Management',na=False), 'Project_Management'] ='1'\n",
    "sf.loc[sf['Project_Management'].str.contains('NaN',na=True), 'Project_Management'] ='0'\n",
    "sf['Risk_Management'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Risk Management',na=False), 'Risk_Management'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('RiskManagement',na=False), 'Risk_Management'] ='1'\n",
    "sf.loc[sf['Risk_Management'].str.contains('Nan',na=True), 'Risk_Management'] ='0'\n",
    "sf['Analysis_Skill'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Analysis Skill',na=False), 'Analysis_Skill'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('AnalysisSkill',na=False), 'Analysis_Skill'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('Analysis',na=False), 'Analysis_Skill'] ='1'\n",
    "sf.loc[sf['Analysis_Skill'].str.contains('NaN',na=True), 'Analysis_Skill'] ='0'\n",
    "sf['Hadoop'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Hadoop',na=False), 'Hadoop'] ='1'\n",
    "sf.loc[sf['Hadoop'].str.contains('NaN',na=True), 'Hadoop'] ='0'\n",
    "sf['SAS'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('SAS',na=False), 'SAS'] ='1'\n",
    "sf.loc[sf['SAS'].str.contains('NaN',na=True), 'SAS'] ='0'\n",
    "sf['Microsoft_Word'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Microsoft Word',na=False), 'Microsoft_Word'] ='1'\n",
    "sf.loc[sf['Microsoft_Word'].str.contains('NaN',na=True), 'Microsoft_Word'] ='0'\n",
    "sf['Microsoft_Office'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Microsoft Office',na=False), 'Microsoft_Office'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('Microsoft office',na=False), 'Microsoft_Office'] ='1'                                                 \n",
    "sf.loc[sf['Microsoft_Office'].str.contains('NaN',na=True), 'Microsoft_Office'] = '0'\n",
    "           \n",
    "\n",
    "#indeed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf['Hive'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Hive',na=False), 'Hive'] ='1'\n",
    "sf.loc[sf['Hive'].str.contains('NaN',na=True), 'Hive'] ='0'\n",
    "sf['AWS'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('AWS',na=False), 'AWS'] ='1'\n",
    "sf.loc[sf['AWS'].str.contains('NaN',na=True), 'AWS'] ='0'\n",
    "sf['Spark'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Spark',na=False), 'Spark'] ='1'\n",
    "sf.loc[sf['Spark'].str.contains('NaN',na=True), 'Spark'] ='0'\n",
    "sf['Data_Mining'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Data Mining',na=False), 'Data_Mining'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('DataMining',na=False), 'Data_Mining'] ='1'\n",
    "sf.loc[sf['Data_Mining'].str.contains('NaN',na=True), 'Data_Mining'] ='0'\n",
    "sf['Predictive_Analytics'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Predictive Analytics',na=False), 'Predictive_Analytics'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('PredictiveAnalytics',na=False), 'Predictive_Analytics'] ='1'\n",
    "sf.loc[sf['Predictive_Analytics'].str.contains('NaN',na=True), 'Predictive_Analytics'] ='0'\n",
    "sf['Machine_Learning'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Machine Learning',na=False), 'Machine_Learning'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('MachineLearning',na=False), 'Machine_Learning'] ='1'\n",
    "\n",
    "sf.loc[sf['Machine_Learning'].str.contains('NaN',na=True), 'Machine_Learning'] ='0'\n",
    "\n",
    "#indeed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf['Pig'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Pig',na=False), 'Pig'] ='1'\n",
    "sf.loc[sf['Pig'].str.contains('NaN',na=True), 'Pig'] ='0'\n",
    "sf['Data_Analysis_Skill'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Data Analysis Skill',na=False), 'Data_Analysis_Skill'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('DataAnalysisSkill',na=False), 'Data_Analysis_Skill'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('Data Analysis',na=False), 'Data_Analysis_Skill'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('DataAnalysis',na=False), 'Data_Analysis_Skill'] ='1'\n",
    "sf.loc[sf['Data_Analysis_Skill'].str.contains('NaN',na=True), 'Data_Analysis_Skill'] ='0'\n",
    "sf['Communication_Skill'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Communication Skill',na=False), 'Communication_Skill'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('CommunicationSkill',na=False), 'Communication_Skill'] ='1'\n",
    "\n",
    "sf.loc[sf['Communication_Skill'].str.contains('NaN',na=True), 'Communication_Skill'] ='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.loc[sf['Job_Description'].str.contains('matlab',na=False), 'Matlab'] ='1'\n",
    "sf.loc[sf['Matlab'].str.contains('NaN',na=True), 'Matlab'] ='0'\n",
    "sf['Scala'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Scala',na=False), 'Scala'] ='1'\n",
    "sf.loc[sf['Scala'].str.contains('NaN',na=True), 'Scala'] ='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Education\n",
    "sf['Bachelor_Degree'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Bachelor',na=False), 'Bachelor_Degree'] ='1'\n",
    "sf.loc[sf['Bachelor_Degree'].str.contains('NaN',na=True), 'Bachelor_Degree'] ='0'\n",
    "sf['Master_Degree'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Master Degree',na=False), 'Master_Degree'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('Master',na=False), 'Master_Degree'] ='1'\n",
    "sf.loc[sf['Master_Degree'].str.contains('NaN',na=True), 'Master_Degree'] ='0'\n",
    "\n",
    "sf['Diploma_GED'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Diploma',na=False), 'Diploma_GED'] ='1'\n",
    "sf.loc[sf['Job_Description'].str.contains('GED',na=False), 'Diploma_GED'] ='1'\n",
    "\n",
    "sf.loc[sf['Diploma_GED'].str.contains('NaN',na=True), 'Diploma_GED'] ='0'\n",
    "\n",
    "sf['Doctoral_Degree'] = np.nan\n",
    "sf.loc[sf['Job_Description'].str.contains('Doctoral',na=False), 'Doctoral_Degree'] ='1'\n",
    "sf.loc[sf['Doctoral_Degree'].str.contains('NaN',na=True), 'Doctoral_Degree'] ='0'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And that’s it! The final step was to save my data as a cleaned csv to make it easier to load and begin my modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.to_csv('sf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1294, 37)\n"
     ]
    }
   ],
   "source": [
    "#sf.info()\n",
    "print(sf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
